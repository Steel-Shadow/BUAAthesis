% !Mode:: "TeX:UTF-8"
\chapter*{结论\markboth{结论}{}}
\addcontentsline{toc}{chapter}{结论}

该文提出了一种新型框架 Big Little Decoder（BiLD），这是一个无需额外训练或修改现有模型就能减少各种文本生成任务的端到端推理延迟的框架。BiLD 将大小解码器模型结合在一起，从而更高效地生成文本。BiLD 从小模型开始推理，小模型在大部分时间内以自回归方式运行，以较低的推理成本生成文本。而大模型则以非自回归方式运行，以完善小型模型的不准确预测。BiLD 包含两种策略，Fallback 策略使得小模型不确定时，将控制权交给大模型， Rollback 策略允许大模型修正小模型不准确的预测。BiLD 在机器翻译、摘要和语言建模文本生成场景中进行了评估。在 NVIDIA Titan Xp GPU 上运行时，BiLD 在保持生成质量时，平均速度提高为 1.52 倍，在某些任务上达到了 2.18 倍。此外，在允许质量下降 $1\%$ 的情况下，BiLD 的平均速度提高为 1.76 倍，某些任务的速度提高为 2.38 倍。总之，该文通过创新性地设计 BiLD 框架，在保持了与现有模型的兼容性的同时，有效地提高了文本生成任务的推理效率，为 NLP 领域的研究和应用提供了有益的思路和方法。
