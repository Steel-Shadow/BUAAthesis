% !Mode:: "TeX:UTF-8"
\chapter*{结论\markboth{结论}{}}
\addcontentsline{toc}{chapter}{结论}

该文提出了一种新型框架 Big Little Decoder（BiLD），这是一个无需额外训练或修改现有模型就能减少各种文本生成任务的端到端推理延迟的框架。从本质上讲，BiLD 将大小解码器模型结合在一起，从而更高效地生成文本。BiLD 从一个小型模型开始推理，小模型在大部分时间内以自回归方式运行，以较低的推理成本生成文本。而大型模型则以非自回归方式执行，以完善小型模型的不准确预测。BiLD 包含两种策略，一种是 Fallback 策略（当小模型不确定时，将控制权交给大模型），另一种是 Rollback 策略（允许大模型恢复小模型不准确的预测）。BiLD 在机器翻译、摘要和语言建模文本生成场景中进行了评估。在 NVIDIA Titan Xp GPU 上运行时，BiLD 的性能没有下降，平均速度提高为 1.52 倍，在某些任务上达到了 2.18 倍。此外，在允许性能下降 1 点的情况下，BiLD 的平均速度提高了 1.76 倍，某些任务的速度提高了 2.38 倍。总之，该文通过创新性地设计 BiLD 框架，在保持了与现有模型的兼容性的同时，有效地提高了文本生成任务的推理效率，为 NLP 领域的研究和应用提供了有益的思路和方法。
